{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T05:59:05.638583Z",
     "start_time": "2024-03-19T05:59:05.630280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import torchmetrics.functional as metrics\n",
    "import os\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1f1a0dd6baefebc7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "folder_path = '../train/train'\n",
    "target_data = []\n",
    "img_data = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_data.append(encoding_label)\n",
    "                        img_data.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0bb845a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " '.DS_Store',\n",
       " 'sad',\n",
       " 'fear',\n",
       " 'surprise',\n",
       " 'neutral',\n",
       " 'angry',\n",
       " 'disgust']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7255dfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 28709)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_data), len(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "36bf3326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_data), type(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af2547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "feb62010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bd1feae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42352941, 0.3254902 , 0.24705882, ..., 0.45490196, 0.47843137,\n",
       "        0.47843137],\n",
       "       [0.5372549 , 0.55686275, 0.62352941, ..., 0.74901961, 0.75294118,\n",
       "        0.75294118],\n",
       "       [0.43529412, 0.58039216, 0.60784314, ..., 0.22352941, 0.21960784,\n",
       "        0.23529412],\n",
       "       ...,\n",
       "       [0.17647059, 0.17254902, 0.16862745, ..., 0.68627451, 0.77647059,\n",
       "        0.8627451 ],\n",
       "       [0.23921569, 0.15294118, 0.23921569, ..., 0.63921569, 0.63137255,\n",
       "        0.62745098],\n",
       "       [1.        , 0.98431373, 1.        , ..., 0.69803922, 0.70588235,\n",
       "        0.75686275]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(img_data)\n",
    "b = a/255.\n",
    "c = b.reshape(-1,48*48)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "90888623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2304)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "016fc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_target = np.array(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "75327356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_target = torch.from_numpy(norm_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c0a0a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature = np.array(img_data)/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "41b29f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature = torch.tensor(c, dtype=torch.float32)\n",
    "norm_target = torch.tensor(norm_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7e03ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_feature = torch.from_numpy(norm_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f98cf5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7215\n",
       "5    4965\n",
       "2    4830\n",
       "3    4097\n",
       "6    3995\n",
       "4    3171\n",
       "7     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(norm_target).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3b159710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.Series(norm_target)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2b601fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "4    4965\n",
       "5    4830\n",
       "2    4097\n",
       "0    3995\n",
       "6    3171\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_targetReplace = pd.Series(norm_target).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "norm_targetReplace.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "414fefdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28709, 2304]), torch.Size([28709]))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_feature.shape, norm_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "75adfdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        self.feature=torch.FloatTensor(x_data)\n",
    "        self.target=torch.LongTensor(y_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c77a96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset= DLDataset(norm_feature, norm_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "343847c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS = random_split(all_dataset, [0.8,0.2], generator=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b2ad9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../test/test'\n",
    "test_target_data = []\n",
    "test_img_data = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    test_image = Image.open(file)\n",
    "                    test_image_array = np.array(image)\n",
    "                    test_target_data.append(encoding_label)\n",
    "                    test_img_data.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "6d4a8a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "4    1233\n",
       "2    1024\n",
       "5     958\n",
       "3     831\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_target_data).unique()\n",
    "pd.Series(test_target_data).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e833dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test_target = np.array(test_target_data)\n",
    "norm_test_feature = np.array(test_img_data)/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6ea967c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testDS= DLDataset(norm_test_feature, norm_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eac3547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "trainDL = DataLoader(trainDS, batch_size=batch, drop_last=True)\n",
    "validDL = DataLoader(validDS, batch_size=batch, drop_last=True)\n",
    "testDL = DataLoader(testDS, batch_size=batch, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "17cd2d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22968, 5741, 239)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDS), len(validDS), len(testDL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1f3d0e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 7, 7, 7])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a1c7f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model1(nn.Module):\n",
    "    \n",
    "    # 모델 구조 설정\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_dim, 100)\n",
    "        self.relu = nn.ReLU()  # 0보다 작거나 같으면 0 / 0보다 크면 1\n",
    "        self.hidden_layer = nn.Linear(100, 27) \n",
    "        self.output_layer = nn.Linear(27, out_dim) \n",
    "        \n",
    "    # 순방향 학습 진행 콜백 함수\n",
    "    def forward(self, x): # 입력데이터 : x\n",
    "        y = self.input_layer(x)   # W1*X1 + W2*X2 + ..Wm*Xm +b 100개 반환\n",
    "        \n",
    "        y = self.relu(y)          # relu() 결과 100개 반환  \n",
    "        \n",
    "        y = self.hidden_layer(y)   # W1*X1 + W2*X2 + ..Wm*Xm +b 27개 반환\n",
    "        \n",
    "        y = self.relu(y)          # relu() 결과 27개 반환\n",
    "        \n",
    "        y = self.output_layer(y)   # W1*X1 + W2*X2 + ..Wm*Xm +b 3개 반환\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7b5af18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "IN_DIM = all_dataset.feature.shape[1]\n",
    "OUT_DIM = len(torch.unique(all_dataset.target))  # or len(np.unique(targetNP) or tragetDF.nunique()\n",
    "\n",
    "model = Model1(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "OPTIMIZER = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8e8356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_feature = torch.DoubleTensor(norm_feature)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a3a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b764efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataLoader):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화\n",
    "    model.train() \n",
    "    \n",
    "    # 배치크기만큼 학습진행 및 저장\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for cnt, (feature, target) in enumerate(dataLoader):\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        # 학습\n",
    "        pre_target = model(norm_feature)\n",
    "\n",
    "        # 손실계산\n",
    "        loss = LOSS_FUNCTION(pre_target,target)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 정확도 \n",
    "        acc = metrics.accuracy(pre_target, target, task = 'multiclass', num_classes=len(torch.unique(all_dataset.target)))\n",
    "        train_acc += acc.item()\n",
    "        \n",
    "        # W, b 업데이트 \n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        # 배치 사이즈 단위 학습 진행 메시지 출력\n",
    "        # print(f'[{cnt}] : [Train batch loss] ==> {loss}')\n",
    "\n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    print(f'[Train loss] ==> {train_loss/ len(dataLoader)}    [Train Accuracy] ==> {train_acc / len(dataLoader)}')\n",
    "    \n",
    "    return train_loss/ len(dataLoader), train_acc / len(dataLoader)\n",
    "    \n",
    "# train_loss, train_acc = training(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7e739419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(dataLoader):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 비활성화\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 배치크기만큼 학습진행\n",
    "        val_loss = 0    \n",
    "        val_acc = 0\n",
    "        for cnt, (feature, target) in enumerate(dataLoader):\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            # 학습\n",
    "            pre_target = model(norm_feature)\n",
    "    \n",
    "            # 손실계산\n",
    "            loss = LOSS_FUNCTION(pre_target,target)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # 정확도 \n",
    "            acc = metrics.accuracy(pre_target, target, task = 'multiclass', num_classes=len(torch.unique(all_dataset.target)))\n",
    "            val_acc += acc.item()\n",
    "              # 배치 사이즈 단위 학습 진행 메시지 출력\n",
    "            # print(f'[{cnt}] : [Train batch loss] ==> {loss}')\n",
    "\n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    print(f'[Valid loss] ==> {val_loss/ len(dataLoader)}    [Valid Accuracy] ==> {val_acc / len(dataLoader)}')\n",
    "    \n",
    "    return val_loss/ len(dataLoader), val_acc / len(dataLoader)\n",
    "    \n",
    "# val_loss, val_acc = testing(validDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ec2063fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "077c5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (28709) to match target batch_size (30).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[338], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 검증\u001b[39;00m\n\u001b[1;32m     10\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m testing(validDL)\n",
      "Cell \u001b[0;32mIn[335], line 14\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataLoader)\u001b[0m\n\u001b[1;32m     11\u001b[0m pre_target \u001b[38;5;241m=\u001b[39m model(norm_feature)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 손실계산\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mLOSS_FUNCTION\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 정확도 \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (28709) to match target batch_size (30)."
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "min_loss = 100.0  # 초기 최소 손실 설정\n",
    "cnt = 0\n",
    "for eps in range(EPOCHS):\n",
    "    print(f'[{eps+1}/{EPOCHS}]')\n",
    "    # 학습\n",
    "    train_loss, train_acc = training(trainDL)\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = testing(validDL)\n",
    "\n",
    "    # 최소 손실 업데이트\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt+=1\n",
    "\n",
    "    # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 2:\n",
    "        print(f\"Early stopping at epoch {eps}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594c776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba09af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d9932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00d6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
