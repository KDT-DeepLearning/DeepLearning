{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/sml/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <ABE0EE74-6D97-3B8C-B690-C44754774FBC> /Users/sml/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <6A598D74-186E-3808-8921-63BA99511723> /Users/sml/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import torchmetrics.functional as metrics\n",
    "import os\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../train/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m target_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m img_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoding_label,label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m      6\u001b[0m     label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, label)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(label_path):  \u001b[38;5;66;03m# 디렉토리인 경우에만 진입\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../train/train'"
     ]
    }
   ],
   "source": [
    "# 학습 검증용 데이터\n",
    "folder_path = '../train/train'\n",
    "target_data = []\n",
    "img_data = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_data.append(encoding_label)\n",
    "                        img_data.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터\n",
    "folder_path = '../test/test'\n",
    "target_test = []\n",
    "img_test = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_test.append(encoding_label)\n",
    "                        img_test.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 정규화\n",
    "x_data = np.array(img_data)/255.\n",
    "x_data = x_data.reshape((-1,48*48))\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7178, 2304)\n"
     ]
    }
   ],
   "source": [
    "x_data_test = np.array(img_test)/255.\n",
    "x_data_test = x_data_test.reshape((-1,48*48))\n",
    "print(x_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "4    4965\n",
       "5    4830\n",
       "2    4097\n",
       "0    3995\n",
       "6    3171\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = pd.Series(target_data).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1774\n",
       "1    1247\n",
       "6    1233\n",
       "5    1024\n",
       "4     958\n",
       "2     831\n",
       "0     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = pd.Series(target_test).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 클래스 생성\n",
    "class DLdataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x_data,y_data):\n",
    "        super().__init__()\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.feature[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = DLdataset(x_data,target_data)\n",
    "dataset_test = DLdataset(x_data_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 검증용 데이터 준비\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS = random_split(dataset, [0.8,0.2], generator=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치사이즈 32\n",
    "BATCH = 32\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH)\n",
    "validDL = DataLoader(validDS, batch_size=BATCH)\n",
    "testDL = DataLoader(dataset_test, batch_size=BATCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN, OUT):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(IN, 128) \n",
    "        self.af = nn.ReLU()\n",
    "        self.hidden = nn.Linear(128, 32)\n",
    "        self.output = nn.Linear(32, OUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.input(x)\n",
    "        y = self.af(y)\n",
    "        y = self.hidden(y)\n",
    "        y = self.af(y)\n",
    "        y = self.output(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "IN = dataset.feature.shape[1]\n",
    "OUT = pd.Series(target_data).nunique()\n",
    "\n",
    "# 모델 생성\n",
    "model  = Model(IN,OUT)\n",
    "\n",
    "# 손실함수\n",
    "LF = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 옵티마이저\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 스케줄러\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    train_report=[[], []]\n",
    "    for (feature, target) in dataLoader:\n",
    "\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_target = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LF(pre_target, target)\n",
    "        train_report[0].append(loss)\n",
    "  \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    loss_score = sum(train_report[0])/len(train_report[0])\n",
    "    acc_score = sum(train_report[1])/len(train_report[1])\n",
    "    print(f'[Train loss] ==> {loss_score}    [Train Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(dataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_report=[[], []]\n",
    "        for (feature, target)  in dataLoader:\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # 학습\n",
    "            pre_target = model(feature)\n",
    "            \n",
    "            # 손실계산\n",
    "            loss = LF(pre_target, target)\n",
    "            test_report[0].append(loss)\n",
    "      \n",
    "            # 성능 평가\n",
    "            acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "            test_report[1].append(acc)\n",
    "    \n",
    "    loss_score = sum(test_report[0])/len(test_report[0])\n",
    "    acc_score = sum(test_report[1])/len(test_report[1])\n",
    "\n",
    "    print(f'[Test loss] ==> {loss_score}    [Test Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]\n",
      "[Train loss] ==> 1.742274522781372    [Train Accuracy] ==> 0.29475685954093933\n",
      "[Test loss] ==> 1.7246193885803223    [Test Accuracy] ==> 0.3150908052921295\n",
      "[2/100]\n",
      "[Train loss] ==> 1.697144627571106    [Train Accuracy] ==> 0.3259778320789337\n",
      "[Test loss] ==> 1.681361436843872    [Test Accuracy] ==> 0.3409455120563507\n",
      "[3/100]\n",
      "[Train loss] ==> 1.670581579208374    [Train Accuracy] ==> 0.33845463395118713\n",
      "[Test loss] ==> 1.6806451082229614    [Test Accuracy] ==> 0.33721956610679626\n",
      "[4/100]\n",
      "[Train loss] ==> 1.6505004167556763    [Train Accuracy] ==> 0.35094591975212097\n",
      "[Test loss] ==> 1.6668769121170044    [Test Accuracy] ==> 0.3443376123905182\n",
      "[5/100]\n",
      "[Train loss] ==> 1.6349468231201172    [Train Accuracy] ==> 0.3579532206058502\n",
      "[Test loss] ==> 1.666142463684082    [Test Accuracy] ==> 0.34493857622146606\n",
      "[6/100]\n",
      "[Train loss] ==> 1.6225495338439941    [Train Accuracy] ==> 0.36012938618659973\n",
      "[Test loss] ==> 1.673123836517334    [Test Accuracy] ==> 0.3357371985912323\n",
      "[7/100]\n",
      "[Train loss] ==> 1.6105889081954956    [Train Accuracy] ==> 0.3687761127948761\n",
      "[Test loss] ==> 1.6514556407928467    [Test Accuracy] ==> 0.34206730127334595\n",
      "[8/100]\n",
      "[Train loss] ==> 1.5978971719741821    [Train Accuracy] ==> 0.3736943006515503\n",
      "[Test loss] ==> 1.6562988758087158    [Test Accuracy] ==> 0.34667468070983887\n",
      "[9/100]\n",
      "[Train loss] ==> 1.5866754055023193    [Train Accuracy] ==> 0.3759865462779999\n",
      "[Test loss] ==> 1.6662299633026123    [Test Accuracy] ==> 0.34910523891448975\n",
      "[10/100]\n",
      "[Train loss] ==> 1.5771448612213135    [Train Accuracy] ==> 0.382790744304657\n",
      "[Test loss] ==> 1.6577948331832886    [Test Accuracy] ==> 0.3530983030796051\n",
      "[11/100]\n",
      "[Train loss] ==> 1.57162344455719    [Train Accuracy] ==> 0.3841690123081207\n",
      "[Test loss] ==> 1.644797444343567    [Test Accuracy] ==> 0.35500800609588623\n",
      "[12/100]\n",
      "[Train loss] ==> 1.5602587461471558    [Train Accuracy] ==> 0.38940632343292236\n",
      "[Test loss] ==> 1.6327178478240967    [Test Accuracy] ==> 0.360216349363327\n",
      "[13/100]\n",
      "[Train loss] ==> 1.5537651777267456    [Train Accuracy] ==> 0.39314937591552734\n",
      "[Test loss] ==> 1.627089262008667    [Test Accuracy] ==> 0.3635149598121643\n",
      "[14/100]\n"
     ]
    }
   ],
   "source": [
    "min_loss = 100.0  # 초기 최소 손실 설정\n",
    "cnt = 0\n",
    "for eps in range(EPOCHS):\n",
    "    print(f'[{eps+1}/{EPOCHS}]')\n",
    "    # 학습\n",
    "    train_loss, train_acc = training(trainDL)\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = testing(validDL)\n",
    "    \n",
    "    # 최소 손실 업데이트\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        cnt = 0\n",
    "        torch.save(model.state_dict(), \"my_trained_model.pth\")\n",
    "\n",
    "    else:\n",
    "        cnt+=1\n",
    "\n",
    "    # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 5:\n",
    "        print(f\"Early stopping at epoch {eps}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train loss] ==> 1.5807474851608276    [Train Accuracy] ==> 0.38126739859580994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.5807, grad_fn=<DivBackward0>), tensor(0.3813))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test loss] ==> 1.6190330982208252    [Test Accuracy] ==> 0.36282050609588623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.6190), tensor(0.3628))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(validDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting(testDL, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m BATCHLIST \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m102\u001b[39m, \u001b[38;5;241m502\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BATCH \u001b[38;5;129;01min\u001b[39;00m BATCHLIST:\n\u001b[0;32m----> 6\u001b[0m     trainDL \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(trainDS, batch_size\u001b[38;5;241m=\u001b[39mBATCH)\n\u001b[1;32m      7\u001b[0m     validDL \u001b[38;5;241m=\u001b[39m DataLoader(validDS, batch_size\u001b[38;5;241m=\u001b[39mBATCH)\n\u001b[1;32m      8\u001b[0m     testDL \u001b[38;5;241m=\u001b[39m DataLoader(dataset_test, batch_size\u001b[38;5;241m=\u001b[39mBATCH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# 배치사이즈 32\n",
    "\n",
    "BATCHLIST = [12, 32, 52, 102, 502]\n",
    "\n",
    "for BATCH in BATCHLIST:\n",
    "    trainDL = DataLoader(trainDS, batch_size=BATCH)\n",
    "    validDL = DataLoader(validDS, batch_size=BATCH)\n",
    "    testDL = DataLoader(dataset_test, batch_size=BATCH)\n",
    "\n",
    "\n",
    "    min_loss = 100.0  # 초기 최소 손실 설정\n",
    "    cnt = 0\n",
    "    for eps in range(EPOCHS):\n",
    "        print(f'[{eps+1}/{EPOCHS}]')\n",
    "        # 학습\n",
    "        train_loss, train_acc = training(trainDL)\n",
    "\n",
    "        # 검증\n",
    "        val_loss, val_acc = testing(validDL)\n",
    "        \n",
    "        # 최소 손실 업데이트\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            cnt = 0\n",
    "            torch.save(model.state_dict(), \"my_trained_model.pth\")\n",
    "\n",
    "        else:\n",
    "            cnt+=1\n",
    "\n",
    "        # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "        if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 5:\n",
    "            print(f\"Early stopping at epoch {eps}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
