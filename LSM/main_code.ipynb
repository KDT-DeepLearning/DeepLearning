{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:25.500109800Z",
     "start_time": "2024-03-19T11:45:20.233301500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import torchmetrics.functional as metrics\n",
    "import os\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b1c2d16ff2a8a4c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:30.022692300Z",
     "start_time": "2024-03-19T11:45:25.505362900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 학습 검증용 데이터\n",
    "folder_path = '../train/train'\n",
    "target_data = []\n",
    "img_data = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_data.append(encoding_label)\n",
    "                        img_data.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c0666d2668b82d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.096959500Z",
     "start_time": "2024-03-19T11:45:30.024741500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 테스트용 데이터\n",
    "folder_path = '../test/test'\n",
    "target_test = []\n",
    "img_test = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_test.append(encoding_label)\n",
    "                        img_test.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5360f693ce4053fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.112471900Z",
     "start_time": "2024-03-19T11:45:34.097983400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "2    1024\n",
       "3     831\n",
       "4    1233\n",
       "5     958\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a4fc72c7b729717d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.144790600Z",
     "start_time": "2024-03-19T11:45:34.115624600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da8e72ad1202979c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.145861Z",
     "start_time": "2024-03-19T11:45:34.130222900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7215\n",
       "2    4830\n",
       "3    4097\n",
       "4    3171\n",
       "5    4965\n",
       "6    3995\n",
       "7     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(target_data).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e89dc5ed8cf89a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.203358400Z",
     "start_time": "2024-03-19T11:45:34.145861Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지의 너비: 48\n",
      "이미지의 높이: 48\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"../test/test/angry/PrivateTest_1488292.jpg\")\n",
    "\n",
    "# 이미지의 너비와 높이 확인\n",
    "width, height = image.size\n",
    "print(\"이미지의 너비:\", width)\n",
    "print(\"이미지의 높이:\", height)\n",
    "\n",
    "# 이미지 크기 48 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36cffaf0592f9f35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.367293200Z",
     "start_time": "2024-03-19T11:45:34.162539500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 정규화\n",
    "x_data = np.array(img_data)/255.\n",
    "x_data = x_data.reshape((-1,48*48))\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "193833da3dcae4d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.382380500Z",
     "start_time": "2024-03-19T11:45:34.359413Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 원핫 인코딩\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# y_data = OneHotEncoder(sparse_output=False).fit_transform(np.array(target_data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "073dce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(x_data).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8eeef0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "4    4965\n",
       "5    4830\n",
       "2    4097\n",
       "0    3995\n",
       "6    3171\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = pd.Series(target_data).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "549caf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "4    1233\n",
       "2    1024\n",
       "5     958\n",
       "3     831\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e2ce99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1774\n",
       "1    1247\n",
       "6    1233\n",
       "5    1024\n",
       "4     958\n",
       "2     831\n",
       "0     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = pd.Series(target_test).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "85513720cbde38df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.418492200Z",
     "start_time": "2024-03-19T11:45:34.376025300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 데이터 클래스 생성\n",
    "class DLdataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x_data,y_data):\n",
    "        super().__init__()\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.feature[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9aad114569f37c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.476239300Z",
     "start_time": "2024-03-19T11:45:34.388596500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = DLdataset(x_data,target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test_target = np.array(test_target_data)\n",
    "norm_test_feature = np.array(test_img_data)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f881fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDS= DLDataset(norm_test_feature, norm_test_target)\n",
    "testDL = DataLoader(testDS, batch_size=batch, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91f009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "2    1024\n",
       "3     831\n",
       "4    1233\n",
       "5     958\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5ca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7215\n",
       "2    4830\n",
       "3    4097\n",
       "4    3171\n",
       "5    4965\n",
       "6    3995\n",
       "7     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_data).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cb6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지의 너비: 48\n",
      "이미지의 높이: 48\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"../test/test/angry/PrivateTest_1488292.jpg\")\n",
    "\n",
    "# 이미지의 너비와 높이 확인\n",
    "width, height = image.size\n",
    "print(\"이미지의 너비:\", width)\n",
    "print(\"이미지의 높이:\", height)\n",
    "\n",
    "# 이미지 크기 48 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 정규화\n",
    "x_data = np.array(img_data)/255.\n",
    "x_data = x_data.reshape((-1,48*48))\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# y_data = OneHotEncoder(sparse_output=False).fit_transform(np.array(target_data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd817622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(x_data).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63274a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "4    4965\n",
       "5    4830\n",
       "2    4097\n",
       "0    3995\n",
       "6    3171\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_data = pd.Series(target_data).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ce7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "4    1233\n",
       "2    1024\n",
       "5     958\n",
       "3     831\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09298d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1774\n",
       "1    1247\n",
       "6    1233\n",
       "5    1024\n",
       "4     958\n",
       "2     831\n",
       "0     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_test = pd.Series(target_test).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 클래스 생성\n",
    "class DLdataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x_data,y_data):\n",
    "        super().__init__()\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.feature[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = DLdataset(x_data,target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b11afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 검증용 데이터 준비\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS = random_split(dataset, [0.8,0.2], generator=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치사이즈 32\n",
    "BATCH = 32\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH)\n",
    "validDL = DataLoader(validDS, batch_size=BATCH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef980b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN, OUT):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(IN, 128) \n",
    "        self.af = nn.ReLU()\n",
    "        self.hidden = nn.Linear(128, 32)\n",
    "        self.output = nn.Linear(32, OUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.input(x)\n",
    "        y = self.af(y)\n",
    "        y = self.hidden(y)\n",
    "        y = self.af(y)\n",
    "        y = self.output(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "IN = dataset.feature.shape[1]\n",
    "OUT = pd.Series(target_data).nunique()\n",
    "\n",
    "# 모델 생성\n",
    "model  = Model(IN,OUT)\n",
    "\n",
    "# 손실함수\n",
    "LF = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 옵티마이저\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 스케줄러\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    train_report=[[], []]\n",
    "    for (feature, target) in dataLoader:\n",
    "\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_target = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LF(pre_target, target)\n",
    "        train_report[0].append(loss)\n",
    "  \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    loss_score = sum(train_report[0])/BATCH\n",
    "    acc_score = sum(train_report[1])/BATCH\n",
    "    print(f'[Train loss] ==> {loss_score}    [Train Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train loss] ==> 40.47188186645508    [Train Accuracy] ==> 5.694986820220947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(40.4719, grad_fn=<DivBackward0>), tensor(5.6950))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(dataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_report=[[], []]\n",
    "        for (feature, target)  in dataLoader:\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # 학습\n",
    "            pre_target = model(feature)\n",
    "            \n",
    "            # 손실계산\n",
    "            loss = LF(pre_target, target)\n",
    "            test_report[0].append(loss)\n",
    "      \n",
    "            # 성능 평가\n",
    "            acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "            test_report[1].append(acc)\n",
    "    \n",
    "        loss_score = sum(test_report[0])/BATCH\n",
    "        acc_score = sum(test_report[1])/BATCH\n",
    "\n",
    "    print(f'[Test loss] ==> {loss_score}    [Test Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test loss] ==> 9.980865478515625    [Test Accuracy] ==> 1.5150991678237915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.9809), tensor(1.5151))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing(validDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(dataLoader,n):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, ytrue = dataset[idx][0], dataset[idx][1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ypre = model(img.unsqueeze(0))\n",
    "            ypre = torch.argmax(ypre, dim=1).item()\n",
    "\n",
    "            if ypre == ytrue:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "            if idx < n :\n",
    "                plt.imshow(dataset[idx][0].numpy().reshape(28, 28), cmap='gray_r')\n",
    "                plt.title(f'[{idx+1}] True {ytrue} / Predict {ypre}')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.show()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d16e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]\n",
      "[Train loss] ==> 38.64373779296875    [Train Accuracy] ==> 6.989908695220947\n",
      "[Test loss] ==> 9.523439407348633    [Test Accuracy] ==> 1.8919771909713745\n",
      "[2/100]\n",
      "[Train loss] ==> 37.848960876464844    [Train Accuracy] ==> 7.472005367279053\n",
      "[Test loss] ==> 9.499372482299805    [Test Accuracy] ==> 1.859299898147583\n",
      "[3/100]\n",
      "[Train loss] ==> 37.381629943847656    [Train Accuracy] ==> 7.737630367279053\n",
      "[Test loss] ==> 9.358746528625488    [Test Accuracy] ==> 1.944260835647583\n",
      "[4/100]\n",
      "[Train loss] ==> 36.993003845214844    [Train Accuracy] ==> 7.902669429779053\n",
      "[Test loss] ==> 9.287851333618164    [Test Accuracy] ==> 1.947190523147583\n",
      "[5/100]\n",
      "[Train loss] ==> 36.66273498535156    [Train Accuracy] ==> 8.098958015441895\n",
      "[Test loss] ==> 9.278766632080078    [Test Accuracy] ==> 1.9681490659713745\n",
      "[6/100]\n",
      "[Train loss] ==> 36.39751434326172    [Train Accuracy] ==> 8.179036140441895\n",
      "[Test loss] ==> 9.230303764343262    [Test Accuracy] ==> 1.9827975034713745\n",
      "[7/100]\n",
      "[Train loss] ==> 36.176876068115234    [Train Accuracy] ==> 8.314778327941895\n",
      "[Test loss] ==> 9.150291442871094    [Test Accuracy] ==> 2.020883321762085\n",
      "[8/100]\n",
      "[Train loss] ==> 35.90610122680664    [Train Accuracy] ==> 8.423176765441895\n",
      "[Test loss] ==> 9.097447395324707    [Test Accuracy] ==> 2.074594259262085\n",
      "[9/100]\n",
      "[Train loss] ==> 35.704833984375    [Train Accuracy] ==> 8.472004890441895\n",
      "[Test loss] ==> 9.076226234436035    [Test Accuracy] ==> 2.069185733795166\n",
      "[10/100]\n",
      "[Train loss] ==> 35.54187774658203    [Train Accuracy] ==> 8.578450202941895\n",
      "[Test loss] ==> 9.014222145080566    [Test Accuracy] ==> 2.058969259262085\n",
      "[11/100]\n",
      "[Train loss] ==> 35.41205978393555    [Train Accuracy] ==> 8.595051765441895\n",
      "[Test loss] ==> 8.972073554992676    [Test Accuracy] ==> 2.090219259262085\n",
      "[12/100]\n",
      "[Train loss] ==> 35.217987060546875    [Train Accuracy] ==> 8.691081047058105\n",
      "[Test loss] ==> 8.994077682495117    [Test Accuracy] ==> 2.105844259262085\n",
      "[13/100]\n",
      "[Train loss] ==> 35.06690979003906    [Train Accuracy] ==> 8.750651359558105\n",
      "[Test loss] ==> 8.968539237976074    [Test Accuracy] ==> 2.103891134262085\n",
      "[14/100]\n",
      "[Train loss] ==> 34.94874572753906    [Train Accuracy] ==> 8.82421875\n",
      "[Test loss] ==> 8.994573593139648    [Test Accuracy] ==> 2.099008321762085\n",
      "[15/100]\n",
      "[Train loss] ==> 34.79338455200195    [Train Accuracy] ==> 8.8232421875\n",
      "[Test loss] ==> 8.993178367614746    [Test Accuracy] ==> 2.077523946762085\n",
      "[16/100]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[96], line 6\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n",
      "\u001b[0;32m----> 6\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 검증\u001b[39;00m\n",
      "\u001b[1;32m      9\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m testing(validDL)\n",
      "\n",
      "Cell \u001b[0;32mIn[92], line 23\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataLoader)\u001b[0m\n",
      "\u001b[1;32m     21\u001b[0m     OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;32m---> 23\u001b[0m     \u001b[43mOPTIMIZER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     25\u001b[0m loss_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n",
      "\u001b[1;32m     26\u001b[0m acc_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    383\u001b[0m             )\n",
      "\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n",
      "\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n",
      "\u001b[1;32m    158\u001b[0m         group,\n",
      "\u001b[1;32m    159\u001b[0m         params_with_grad,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n",
      "\u001b[1;32m    164\u001b[0m         state_steps)\n",
      "\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n",
      "\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n",
      "\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n",
      "\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = 100.0  # 초기 최소 손실 설정\n",
    "cnt = 0\n",
    "for eps in range(EPOCHS):\n",
    "    print(f'[{eps+1}/{EPOCHS}]')\n",
    "    # 학습\n",
    "    train_loss, train_acc = training(trainDL)\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = testing(validDL)\n",
    "    \n",
    "    # 최소 손실 업데이트\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt+=1\n",
    "\n",
    "    # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 5:\n",
    "        print(f\"Early stopping at epoch {eps}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83777b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6e2fa1eb877dab53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.497919400Z",
     "start_time": "2024-03-19T11:45:34.479386Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 학습용, 검증용 데이터 준비\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS = random_split(dataset, [0.8,0.2], generator=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "68a80fe0fc61b644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:45:34.506285500Z",
     "start_time": "2024-03-19T11:45:34.492975200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 배치사이즈 32\n",
    "BATCH = 32\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH)\n",
    "validDL = DataLoader(validDS, batch_size=BATCH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc2b3a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f76ce632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c32ed89c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DLDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testDS\u001b[38;5;241m=\u001b[39m \u001b[43mDLDataset\u001b[49m(norm_test_feature, norm_test_target)\n\u001b[1;32m      2\u001b[0m testDL \u001b[38;5;241m=\u001b[39m DataLoader(testDS, batch_size\u001b[38;5;241m=\u001b[39mbatch, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DLDataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import torchmetrics.functional as metrics\n",
    "import os\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadadc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 검증용 데이터\n",
    "folder_path = '../train/train'\n",
    "target_data = []\n",
    "img_data = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_data.append(encoding_label)\n",
    "                        img_data.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626362ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터\n",
    "folder_path = '../test/test'\n",
    "target_test = []\n",
    "img_test = []\n",
    "for encoding_label,label in enumerate(os.listdir(folder_path)):\n",
    "    label_path = os.path.join(folder_path, label)\n",
    "    if os.path.isdir(label_path):  # 디렉토리인 경우에만 진입\n",
    "        for img in os.listdir(folder_path+'/'+label):\n",
    "            image_path = os.path.join(folder_path,label,img)\n",
    "            if os.path.isfile(image_path):  # 파일인 경우에만 진입\n",
    "                with open(image_path, 'rb') as file:\n",
    "                    image = Image.open(file)\n",
    "                    width, height = image.size\n",
    "                    if width == 48 and height == 48:\n",
    "                        image_array = np.array(image)\n",
    "                        target_test.append(encoding_label)\n",
    "                        img_test.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56307c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "2    1024\n",
       "3     831\n",
       "4    1233\n",
       "5     958\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f34ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f45b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7215\n",
       "2    4830\n",
       "3    4097\n",
       "4    3171\n",
       "5    4965\n",
       "6    3995\n",
       "7     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_data).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3099a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지의 너비: 48\n",
      "이미지의 높이: 48\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"../test/test/angry/PrivateTest_1488292.jpg\")\n",
    "\n",
    "# 이미지의 너비와 높이 확인\n",
    "width, height = image.size\n",
    "print(\"이미지의 너비:\", width)\n",
    "print(\"이미지의 높이:\", height)\n",
    "\n",
    "# 이미지 크기 48 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b293fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 정규화\n",
    "x_data = np.array(img_data)/255.\n",
    "x_data = x_data.reshape((-1,48*48))\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edc347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# y_data = OneHotEncoder(sparse_output=False).fit_transform(np.array(target_data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(x_data).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de321fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7215\n",
       "4    4965\n",
       "5    4830\n",
       "2    4097\n",
       "0    3995\n",
       "6    3171\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_data = pd.Series(target_data).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab5005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1774\n",
       "1    1247\n",
       "4    1233\n",
       "2    1024\n",
       "5     958\n",
       "3     831\n",
       "6     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(target_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f6f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1774\n",
       "1    1247\n",
       "6    1233\n",
       "5    1024\n",
       "4     958\n",
       "2     831\n",
       "0     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_test = pd.Series(target_test).replace({0:3, 5:4, 2:5, 3:2, 6:0, 4:6, 7:1})\n",
    "target_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 클래스 생성\n",
    "class DLdataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x_data,y_data):\n",
    "        super().__init__()\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.feature[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ecf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = DLdataset(x_data,target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c505e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 검증용 데이터 준비\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "trainDS, validDS = random_split(dataset, [0.8,0.2], generator=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f458ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치사이즈 32\n",
    "BATCH = 32\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH)\n",
    "validDL = DataLoader(validDS, batch_size=BATCH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN, OUT):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(IN, 128) \n",
    "        self.af = nn.ReLU()\n",
    "        self.hidden = nn.Linear(128, 32)\n",
    "        self.output = nn.Linear(32, OUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.input(x)\n",
    "        y = self.af(y)\n",
    "        y = self.hidden(y)\n",
    "        y = self.af(y)\n",
    "        y = self.output(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a02154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "IN = dataset.feature.shape[1]\n",
    "OUT = pd.Series(target_data).nunique()\n",
    "\n",
    "# 모델 생성\n",
    "model  = Model(IN,OUT)\n",
    "\n",
    "# 손실함수\n",
    "LF = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 옵티마이저\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 스케줄러\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    train_report=[[], []]\n",
    "    for (feature, target) in dataLoader:\n",
    "\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_target = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LF(pre_target, target)\n",
    "        train_report[0].append(loss)\n",
    "  \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    loss_score = sum(train_report[0])/BATCH\n",
    "    acc_score = sum(train_report[1])/BATCH\n",
    "    print(f'[Train loss] ==> {loss_score}    [Train Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train loss] ==> 40.47188186645508    [Train Accuracy] ==> 5.694986820220947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(40.4719, grad_fn=<DivBackward0>), tensor(5.6950))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb21df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(dataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_report=[[], []]\n",
    "        for (feature, target)  in dataLoader:\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # 학습\n",
    "            pre_target = model(feature)\n",
    "            \n",
    "            # 손실계산\n",
    "            loss = LF(pre_target, target)\n",
    "            test_report[0].append(loss)\n",
    "      \n",
    "            # 성능 평가\n",
    "            acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "            test_report[1].append(acc)\n",
    "    \n",
    "        loss_score = sum(test_report[0])/BATCH\n",
    "        acc_score = sum(test_report[1])/BATCH\n",
    "\n",
    "    print(f'[Test loss] ==> {loss_score}    [Test Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00852e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test loss] ==> 9.980865478515625    [Test Accuracy] ==> 1.5150991678237915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.9809), tensor(1.5151))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing(validDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ed8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(dataLoader,n):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, ytrue = dataset[idx][0], dataset[idx][1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ypre = model(img.unsqueeze(0))\n",
    "            ypre = torch.argmax(ypre, dim=1).item()\n",
    "\n",
    "            if ypre == ytrue:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "            if idx < n :\n",
    "                plt.imshow(dataset[idx][0].numpy().reshape(28, 28), cmap='gray_r')\n",
    "                plt.title(f'[{idx+1}] True {ytrue} / Predict {ypre}')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.show()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c1aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]\n",
      "[Train loss] ==> 38.64373779296875    [Train Accuracy] ==> 6.989908695220947\n",
      "[Test loss] ==> 9.523439407348633    [Test Accuracy] ==> 1.8919771909713745\n",
      "[2/100]\n",
      "[Train loss] ==> 37.848960876464844    [Train Accuracy] ==> 7.472005367279053\n",
      "[Test loss] ==> 9.499372482299805    [Test Accuracy] ==> 1.859299898147583\n",
      "[3/100]\n",
      "[Train loss] ==> 37.381629943847656    [Train Accuracy] ==> 7.737630367279053\n",
      "[Test loss] ==> 9.358746528625488    [Test Accuracy] ==> 1.944260835647583\n",
      "[4/100]\n",
      "[Train loss] ==> 36.993003845214844    [Train Accuracy] ==> 7.902669429779053\n",
      "[Test loss] ==> 9.287851333618164    [Test Accuracy] ==> 1.947190523147583\n",
      "[5/100]\n",
      "[Train loss] ==> 36.66273498535156    [Train Accuracy] ==> 8.098958015441895\n",
      "[Test loss] ==> 9.278766632080078    [Test Accuracy] ==> 1.9681490659713745\n",
      "[6/100]\n",
      "[Train loss] ==> 36.39751434326172    [Train Accuracy] ==> 8.179036140441895\n",
      "[Test loss] ==> 9.230303764343262    [Test Accuracy] ==> 1.9827975034713745\n",
      "[7/100]\n",
      "[Train loss] ==> 36.176876068115234    [Train Accuracy] ==> 8.314778327941895\n",
      "[Test loss] ==> 9.150291442871094    [Test Accuracy] ==> 2.020883321762085\n",
      "[8/100]\n",
      "[Train loss] ==> 35.90610122680664    [Train Accuracy] ==> 8.423176765441895\n",
      "[Test loss] ==> 9.097447395324707    [Test Accuracy] ==> 2.074594259262085\n",
      "[9/100]\n",
      "[Train loss] ==> 35.704833984375    [Train Accuracy] ==> 8.472004890441895\n",
      "[Test loss] ==> 9.076226234436035    [Test Accuracy] ==> 2.069185733795166\n",
      "[10/100]\n",
      "[Train loss] ==> 35.54187774658203    [Train Accuracy] ==> 8.578450202941895\n",
      "[Test loss] ==> 9.014222145080566    [Test Accuracy] ==> 2.058969259262085\n",
      "[11/100]\n",
      "[Train loss] ==> 35.41205978393555    [Train Accuracy] ==> 8.595051765441895\n",
      "[Test loss] ==> 8.972073554992676    [Test Accuracy] ==> 2.090219259262085\n",
      "[12/100]\n",
      "[Train loss] ==> 35.217987060546875    [Train Accuracy] ==> 8.691081047058105\n",
      "[Test loss] ==> 8.994077682495117    [Test Accuracy] ==> 2.105844259262085\n",
      "[13/100]\n",
      "[Train loss] ==> 35.06690979003906    [Train Accuracy] ==> 8.750651359558105\n",
      "[Test loss] ==> 8.968539237976074    [Test Accuracy] ==> 2.103891134262085\n",
      "[14/100]\n",
      "[Train loss] ==> 34.94874572753906    [Train Accuracy] ==> 8.82421875\n",
      "[Test loss] ==> 8.994573593139648    [Test Accuracy] ==> 2.099008321762085\n",
      "[15/100]\n",
      "[Train loss] ==> 34.79338455200195    [Train Accuracy] ==> 8.8232421875\n",
      "[Test loss] ==> 8.993178367614746    [Test Accuracy] ==> 2.077523946762085\n",
      "[16/100]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[96], line 6\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n",
      "\u001b[0;32m----> 6\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 검증\u001b[39;00m\n",
      "\u001b[1;32m      9\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m testing(validDL)\n",
      "\n",
      "Cell \u001b[0;32mIn[92], line 23\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataLoader)\u001b[0m\n",
      "\u001b[1;32m     21\u001b[0m     OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;32m---> 23\u001b[0m     \u001b[43mOPTIMIZER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     25\u001b[0m loss_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n",
      "\u001b[1;32m     26\u001b[0m acc_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    383\u001b[0m             )\n",
      "\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n",
      "\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n",
      "\u001b[1;32m    158\u001b[0m         group,\n",
      "\u001b[1;32m    159\u001b[0m         params_with_grad,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n",
      "\u001b[1;32m    164\u001b[0m         state_steps)\n",
      "\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n",
      "\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n",
      "\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n",
      "\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = 100.0  # 초기 최소 손실 설정\n",
    "cnt = 0\n",
    "for eps in range(EPOCHS):\n",
    "    print(f'[{eps+1}/{EPOCHS}]')\n",
    "    # 학습\n",
    "    train_loss, train_acc = training(trainDL)\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = testing(validDL)\n",
    "    \n",
    "    # 최소 손실 업데이트\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt+=1\n",
    "\n",
    "    # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 5:\n",
    "        print(f\"Early stopping at epoch {eps}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a0552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ff31e9b5b98ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:13.978635500Z",
     "start_time": "2024-03-19T11:46:13.966071900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN, OUT):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(IN, 128) \n",
    "        self.af = nn.ReLU()\n",
    "        self.hidden = nn.Linear(128, 32)\n",
    "        self.output = nn.Linear(32, OUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.input(x)\n",
    "        y = self.af(y)\n",
    "        y = self.hidden(y)\n",
    "        y = self.af(y)\n",
    "        y = self.output(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc94170dc9192f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:25.759604700Z",
     "start_time": "2024-03-19T11:46:24.772083700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 학습 준비\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "IN = dataset.feature.shape[1]\n",
    "OUT = pd.Series(target_data).nunique()\n",
    "\n",
    "# 모델 생성\n",
    "model  = Model(IN,OUT)\n",
    "\n",
    "# 손실함수\n",
    "LF = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 옵티마이저\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 스케줄러\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744f199e3b31c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:26.833101900Z",
     "start_time": "2024-03-19T11:46:26.815284600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(dataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    train_report=[[], []]\n",
    "    for (feature, target) in dataLoader:\n",
    "\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_target = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LF(pre_target, target)\n",
    "        train_report[0].append(loss)\n",
    "  \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    loss_score = sum(train_report[0])/BATCH\n",
    "    acc_score = sum(train_report[1])/BATCH\n",
    "    print(f'[Train loss] ==> {loss_score}    [Train Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52be07bf378a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:30.635102600Z",
     "start_time": "2024-03-19T11:46:27.581471Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train loss] ==> 40.47188186645508    [Train Accuracy] ==> 5.694986820220947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(40.4719, grad_fn=<DivBackward0>), tensor(5.6950))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c6b53bc49ca57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:30.670659800Z",
     "start_time": "2024-03-19T11:46:30.637212400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testing(dataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_report=[[], []]\n",
    "        for (feature, target)  in dataLoader:\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # 학습\n",
    "            pre_target = model(feature)\n",
    "            \n",
    "            # 손실계산\n",
    "            loss = LF(pre_target, target)\n",
    "            test_report[0].append(loss)\n",
    "      \n",
    "            # 성능 평가\n",
    "            acc = metrics.accuracy(pre_target.argmax(dim=1), target, task = 'multiclass',num_classes=OUT)\n",
    "            test_report[1].append(acc)\n",
    "    \n",
    "        loss_score = sum(test_report[0])/BATCH\n",
    "        acc_score = sum(test_report[1])/BATCH\n",
    "\n",
    "    print(f'[Test loss] ==> {loss_score}    [Test Accuracy] ==> {acc_score}')\n",
    "    return loss_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bfde8e315dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:46:30.836244Z",
     "start_time": "2024-03-19T11:46:30.649242200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test loss] ==> 9.980865478515625    [Test Accuracy] ==> 1.5150991678237915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.9809), tensor(1.5151))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(validDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50282dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(dataLoader,n):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, ytrue = dataset[idx][0], dataset[idx][1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ypre = model(img.unsqueeze(0))\n",
    "            ypre = torch.argmax(ypre, dim=1).item()\n",
    "\n",
    "            if ypre == ytrue:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "            if idx < n :\n",
    "                plt.imshow(dataset[idx][0].numpy().reshape(28, 28), cmap='gray_r')\n",
    "                plt.title(f'[{idx+1}] True {ytrue} / Predict {ypre}')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.show()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72361f5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testDL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicting(\u001b[43mtestDL\u001b[49m, \u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testDL' is not defined"
     ]
    }
   ],
   "source": [
    "predicting(testDL, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f4740044213ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T11:47:51.513836700Z",
     "start_time": "2024-03-19T11:46:30.834075Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]\n",
      "[Train loss] ==> 38.64373779296875    [Train Accuracy] ==> 6.989908695220947\n",
      "[Test loss] ==> 9.523439407348633    [Test Accuracy] ==> 1.8919771909713745\n",
      "[2/100]\n",
      "[Train loss] ==> 37.848960876464844    [Train Accuracy] ==> 7.472005367279053\n",
      "[Test loss] ==> 9.499372482299805    [Test Accuracy] ==> 1.859299898147583\n",
      "[3/100]\n",
      "[Train loss] ==> 37.381629943847656    [Train Accuracy] ==> 7.737630367279053\n",
      "[Test loss] ==> 9.358746528625488    [Test Accuracy] ==> 1.944260835647583\n",
      "[4/100]\n",
      "[Train loss] ==> 36.993003845214844    [Train Accuracy] ==> 7.902669429779053\n",
      "[Test loss] ==> 9.287851333618164    [Test Accuracy] ==> 1.947190523147583\n",
      "[5/100]\n",
      "[Train loss] ==> 36.66273498535156    [Train Accuracy] ==> 8.098958015441895\n",
      "[Test loss] ==> 9.278766632080078    [Test Accuracy] ==> 1.9681490659713745\n",
      "[6/100]\n",
      "[Train loss] ==> 36.39751434326172    [Train Accuracy] ==> 8.179036140441895\n",
      "[Test loss] ==> 9.230303764343262    [Test Accuracy] ==> 1.9827975034713745\n",
      "[7/100]\n",
      "[Train loss] ==> 36.176876068115234    [Train Accuracy] ==> 8.314778327941895\n",
      "[Test loss] ==> 9.150291442871094    [Test Accuracy] ==> 2.020883321762085\n",
      "[8/100]\n",
      "[Train loss] ==> 35.90610122680664    [Train Accuracy] ==> 8.423176765441895\n",
      "[Test loss] ==> 9.097447395324707    [Test Accuracy] ==> 2.074594259262085\n",
      "[9/100]\n",
      "[Train loss] ==> 35.704833984375    [Train Accuracy] ==> 8.472004890441895\n",
      "[Test loss] ==> 9.076226234436035    [Test Accuracy] ==> 2.069185733795166\n",
      "[10/100]\n",
      "[Train loss] ==> 35.54187774658203    [Train Accuracy] ==> 8.578450202941895\n",
      "[Test loss] ==> 9.014222145080566    [Test Accuracy] ==> 2.058969259262085\n",
      "[11/100]\n",
      "[Train loss] ==> 35.41205978393555    [Train Accuracy] ==> 8.595051765441895\n",
      "[Test loss] ==> 8.972073554992676    [Test Accuracy] ==> 2.090219259262085\n",
      "[12/100]\n",
      "[Train loss] ==> 35.217987060546875    [Train Accuracy] ==> 8.691081047058105\n",
      "[Test loss] ==> 8.994077682495117    [Test Accuracy] ==> 2.105844259262085\n",
      "[13/100]\n",
      "[Train loss] ==> 35.06690979003906    [Train Accuracy] ==> 8.750651359558105\n",
      "[Test loss] ==> 8.968539237976074    [Test Accuracy] ==> 2.103891134262085\n",
      "[14/100]\n",
      "[Train loss] ==> 34.94874572753906    [Train Accuracy] ==> 8.82421875\n",
      "[Test loss] ==> 8.994573593139648    [Test Accuracy] ==> 2.099008321762085\n",
      "[15/100]\n",
      "[Train loss] ==> 34.79338455200195    [Train Accuracy] ==> 8.8232421875\n",
      "[Test loss] ==> 8.993178367614746    [Test Accuracy] ==> 2.077523946762085\n",
      "[16/100]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 검증\u001b[39;00m\n\u001b[1;32m      9\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m testing(validDL)\n",
      "Cell \u001b[0;32mIn[92], line 23\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataLoader)\u001b[0m\n\u001b[1;32m     21\u001b[0m     OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mOPTIMIZER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n\u001b[1;32m     26\u001b[0m acc_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_report[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39mBATCH\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = 100.0  # 초기 최소 손실 설정\n",
    "cnt = 0\n",
    "for eps in range(EPOCHS):\n",
    "    print(f'[{eps+1}/{EPOCHS}]')\n",
    "    # 학습\n",
    "    train_loss, train_acc = training(trainDL)\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = testing(validDL)\n",
    "    \n",
    "    # 최소 손실 업데이트\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt+=1\n",
    "\n",
    "    # 조기 종료 기능 => 조건 : val_loss가 지정된 횟수 이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience or cnt >= 5:\n",
    "        print(f\"Early stopping at epoch {eps}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ae593cf438c47",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T11:45:35.504171600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c8bdc1bec4ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T11:45:35.506238400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
